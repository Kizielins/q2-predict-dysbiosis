{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This document contains commands we used to run different tools in our publication.\n",
    "\n",
    "#### Metagenomic sample pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Trimgalore!\n",
    "\n",
    "# trim_galore --paired <fastq1> <fastq2> -> this command outputs post-QC fastq files\n",
    "\n",
    "## Human contamination removal with bowtie2\n",
    "\n",
    "# wget https://genome-idx.s3.amazonaws.com/bt/GRCh38_noalt_as.zip\n",
    "# unzip GRCh38_noalt_as.zip\n",
    "# bowtie2 -p 8 -x GRCh38_noalt_as -1 <fastq1> -2 <fastq2> --very-sensitive-local --un-conc-gz SAMPLE_host_removed > SAMPLE_mapped_and_unmapped.sam\n",
    "# mv SAMPLE_host_removed.1 SAMPLE_host_removed_R1.fastq.gz\n",
    "# mv SAMPLE_host_removed.2 SAMPLE_host_removed_R2.fastq.gz\n",
    "\n",
    "## Taxonomic assignment with MetaPhlAn\n",
    "\n",
    "# zcat SAMPLE_host_removed_R1.fastq.gz SAMPLE_host_removed_R2.fastq.gz | gzip -c > metagenome.fastq\n",
    "# metaphlan metagenome.fastq --input_type fastq -o profiled_metagenome.txt\n",
    "\n",
    "## Functional prediction with Humann\n",
    "\n",
    "# humann --input metagenome.fastq --output output_metagenome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running different indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Shannon entropy - on species and functions\n",
    "\n",
    "#biom convert -i <profile txt> -o profile.biom --table-type \"Table\" --to-hdf5\n",
    "#qiime tools import --input-path profile.biom --type FeatureTable[Frequency] --output-path profile.qza\n",
    "#qiime diversity alpha --i-table profile.qza --p-metric shannon --o-alpha-diversity profile_shannon.qza\n",
    "#qiime diversity alpha-group-significance --i-alpha-diversity profile_shannon.qza --m-metadata-file metadata.txt --o-visualization profile_shannon.qzv\n",
    "\n",
    "## GMHI\n",
    "\n",
    "#biom convert -i <profile txt> -o profile.biom --table-type \"Table\" --to-hdf5\n",
    "#qiime tools import --input-path profile.biom --type FeatureTable[Frequency] --output-path profile.qza\n",
    "#qiime health-index gmhi-predict-viz --i-table profile.qza --m-metadata-file metadata.txt --o-gmhi-results profile_results --o-gmhi-plot profile_plot\n",
    "\n",
    "## hiPCA\n",
    "\n",
    "# To calculate hiPCA scores, we modified the original MATLAB script by substituting inputs with our files and saved the output values.\n",
    "\n",
    "## Q2PD\n",
    "\n",
    "# python run_q2_predict_dysbiosis.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Index benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Boruta - run on matrix where parameters are values of different indices and the decision variable is health/disease\n",
    "\n",
    "#import pandas as pd\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "#from boruta import BorutaPy\n",
    "#import numpy as np \n",
    "#from sklearn.metrics import roc_curve, roc_auc_score \n",
    "\n",
    "# BorutaPy accepts numpy arrays only, hence the .values attribute\n",
    "#X = pd.read_csv('input.txt', sep=\"\\t\",usecols=[0,1,2,3]).values\n",
    "#y = pd.read_csv('input.txt', sep=\"\\t\",usecols=[4]).values\n",
    "#y = y.ravel()\n",
    "\n",
    "#cols = list(pd.read_csv('input.txt', sep=\"\\t\",usecols=[0,1,2,3]).columns)\n",
    "\n",
    "# define random forest classifier, with utilising all cores and\n",
    "# sampling in proportion to y labels\n",
    "#rf = RandomForestClassifier(n_jobs=-1, class_weight='balanced', max_depth=5)\n",
    "\n",
    "# define Boruta feature selection method\n",
    "#feat_selector = BorutaPy(rf, n_estimators='auto', verbose=0, random_state=1)\n",
    "\n",
    "# find all relevant features - 5 features should be selected\n",
    "#feat_selector.fit(X, y)\n",
    "\n",
    "#print(\"Ranking:\")\n",
    "#print(feat_selector.ranking_)\n",
    "\n",
    "#print(\"\\n------Support and Ranking for each feature------\")\n",
    "#for i in range(len(feat_selector.support_)):\n",
    "#    if feat_selector.support_[i]:\n",
    "#        print(\"Passes the test: \", cols[i],\n",
    "#              \" - Ranking: \", feat_selector.ranking_[i])\n",
    "#    else:\n",
    "#        print(\"Doesn't pass the test: \",\n",
    "#              cols[i], \" - Ranking: \", feat_selector.ranking_[i])        \n",
    "        \n",
    "#X_filtered = feat_selector.transform(np.array(X))\n",
    "#rf.fit(X_filtered, y)\n",
    "#predictions = rf.predict(X_filtered)\n",
    "\n",
    "# create a dataframe with real predictions and values\n",
    "#df = pd.DataFrame({'pred': predictions, 'observed': y})\n",
    "\n",
    "# compute RMSE\n",
    "#mse = ((df['pred'] - df['observed']) ** 2).mean()\n",
    "#rmse = np.sqrt(mse)\n",
    "\n",
    "# RF accuracy and AUC ROC\n",
    "#roc_auc = roc_auc_score(y, predictions) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other tools used in the study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MDFS\n",
    "\n",
    "#data_vector = X\n",
    "#dec_vector = y\n",
    "#dec_vector[dec_vector != 0] = 1\n",
    "#output = mdfs.run(np.array(data_vector), np.array(dec_vector.astype(np.int32)), n_contrast=30, dimensions=2, discretizations=50, range_=0.9)\n",
    "\n",
    "#all_labels = list(X.columns)\n",
    "#important_labels = []\n",
    "#for i in output['relevant_variables']:\n",
    "#    important_labels.append(all_labels[i])\n",
    "#print(important_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SPARCC - separately per project and diagnosis\n",
    "\n",
    "#biom convert -i profile.tsv -o profile.biom --table-type \"Table\" --to-hdf5\n",
    "#qiime tools import --input-path profile.biom --type FeatureTable[Frequency] --output-path profile.qza\n",
    "\n",
    "#qiime SCNIC calculate-correlations --i-table profile.qza --p-method sparcc --o-correlation-table profile_sparcc.qza\n",
    "#qiime tools export --input-path profile_sparcc.qza --output-path profile_sparcc\n",
    "\n",
    "# in python:\n",
    "\n",
    "#sparcc_results = pd.read_csv(\"profile_sparcc/pairwise_comparisons.tsv\", sep=\"\\t\")\n",
    "#sparcc_results = sparcc_results.loc[sparcc_results['r'].abs() >= 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random Forest training\n",
    "\n",
    "#from numpy import mean\n",
    "#from numpy import std\n",
    "#from pandas import read_csv\n",
    "#from sklearn.model_selection import LeaveOneOut\n",
    "#from sklearn.model_selection import cross_val_predict\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "# create loocv procedure\n",
    "#cv = LeaveOneOut()\n",
    "# create model\n",
    "#model = RandomForestClassifier(random_state=1)\n",
    "# evaluate model\n",
    "#scores = cross_val_predict(model, X, y, method='predict_proba', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "#print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
